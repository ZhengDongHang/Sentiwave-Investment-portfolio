import os
import joblib
import numpy as np
from tqdm import tqdm
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVR
from sklearn.multioutput import MultiOutputRegressor

from utils import load_all_data  # ä½ è‡ªå·±çš„æ•°æ®åŠ è½½å‡½æ•°

# -------------- å‚æ•° --------------
folder_path = '../../data/train_data/'  # æ•°æ®è·¯å¾„
save_model_path = 'svr_model.pkl'
max_len = 64

# -------------- åŠ è½½æ•°æ® --------------
print("ğŸ”„ åŠ è½½è®­ç»ƒæ•°æ®...")
all_data = load_all_data(folder_path, if_train=True)

# -------------- æ„é€ æ ·æœ¬ --------------
print("ğŸ”¨ å¤„ç†è®­ç»ƒæ ·æœ¬...")
texts = []
targets = []

for item in tqdm(all_data, desc="æ„å»ºæ ·æœ¬"):
    index = item['index']  # ä¸‰ç»´è¿ç»­æ ‡ç­¾ï¼Œå¦‚ (x1,x2,x3)
    for text in item.get('guba_data', []):
        if len(text) > max_len:
            text = text[:max_len]
        texts.append(text)
        targets.append(index)

targets = np.array(targets)  # (N,3) å½¢çŠ¶

# -------------- ç‰¹å¾æå– --------------
print("ğŸ” æå–æ–‡æœ¬ç‰¹å¾...")
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(texts)

# -------------- æ¨¡å‹è®­ç»ƒ --------------
print("ğŸ‹ï¸ è®­ç»ƒå¤šæ ‡ç­¾å›å½’æ¨¡å‹...")
base_model = LinearSVR()
model = MultiOutputRegressor(base_model)
model.fit(X, targets)

# -------------- ä¿å­˜æ¨¡å‹ --------------
print("ğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°", save_model_path)
joblib.dump((vectorizer, model), save_model_path)

print("âœ… è®­ç»ƒå®Œæˆã€‚")
